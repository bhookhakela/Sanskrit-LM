{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6a05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "text_dir = 'Sans_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2661aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\"\n",
    "for file_name in os.listdir(text_dir):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        with open(os.path.join(text_dir, file_name), 'r', encoding='utf-8') as f:\n",
    "            all_text += f.read() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f3568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = re.sub(r'\\s+', ' ', all_text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fa5dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8507929"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af21fb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028452"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = all_text.split()\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49ca250",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a8efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 7  \n",
    "vocab = [word for word, freq in word_counts.items() if freq >= min_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765c7296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1909b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {word: i for i, word in enumerate(vocab)}\n",
    "index2word = {i: word for word, i in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a90a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [w for w in tokens if w in word2index]\n",
    "data = []\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378242de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,central_words in enumerate(filtered_tokens):\n",
    "  central_word_index = word2index[central_words]\n",
    "  for j in range(-window_size, window_size + 1):\n",
    "    if j!=0 and i+j >= 0 and i+j < len(filtered_tokens):\n",
    "      context_word = filtered_tokens[i+j]\n",
    "      context_word_index = word2index[context_word]\n",
    "      data.append((central_word_index, context_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b005859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecScratch(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2VecScratch, self).__init__()\n",
    "    self.hidden = nn.Linear(vocab_size, embedding_dim, bias = False)\n",
    "    self.output = nn.Linear(embedding_dim, vocab_size, bias = False)\n",
    "  def forward(self, x):\n",
    "    x = self.hidden(x)\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1834e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7137fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68fb0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_word_tensor = torch.tensor([pair[0] for pair in data])\n",
    "context_word_tensor = torch.tensor([pair[1] for pair in data])\n",
    "dataset = TensorDataset(central_word_tensor, context_word_tensor)\n",
    "train_loader = loader = DataLoader(dataset, batch_size = 2048, shuffle = True, num_workers=100, pin_memory=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df665395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Word2VecScratch(vocab_size, 500).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "def get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps, num_cycles=0.5, last_epoch=-1):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        # Cosine decay\n",
    "        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + torch.cos(torch.tensor(progress * 3.1415926535 * num_cycles))))\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "batch_size = 2048\n",
    "total_steps = 300 * len(dataset) // batch_size\n",
    "warmup_steps = int(total_steps * 0.1)  \n",
    "\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ac18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/300\n",
      "  Batch 1142/1142 - Loss: 9.1320\n",
      "→ Epoch 1 finished - Avg Loss: 9.3020\n",
      "✅ Best model saved at epoch 1 with loss 9.3020\n",
      "\n",
      "Epoch 2/300\n",
      "  Batch 1142/1142 - Loss: 7.0535\n",
      "→ Epoch 2 finished - Avg Loss: 8.2640\n",
      "✅ Best model saved at epoch 2 with loss 8.2640\n",
      "\n",
      "Epoch 3/300\n",
      "  Batch 1142/1142 - Loss: 6.7854\n",
      "→ Epoch 3 finished - Avg Loss: 6.9233\n",
      "✅ Best model saved at epoch 3 with loss 6.9233\n",
      "\n",
      "Epoch 4/300\n",
      "  Batch 1142/1142 - Loss: 6.4642\n",
      "→ Epoch 4 finished - Avg Loss: 6.5011\n",
      "✅ Best model saved at epoch 4 with loss 6.5011\n",
      "\n",
      "Epoch 5/300\n",
      "  Batch 549/1142 - Loss: 6.3433\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1142/1142 - Loss: 5.9520\n",
      "→ Epoch 24 finished - Avg Loss: 5.3180\n",
      "✅ Best model saved at epoch 24 with loss 5.3180\n",
      "\n",
      "Epoch 25/300\n",
      "  Batch 1142/1142 - Loss: 5.0424\n",
      "→ Epoch 25 finished - Avg Loss: 5.2697\n",
      "✅ Best model saved at epoch 25 with loss 5.2697\n",
      "\n",
      "Epoch 26/300\n",
      "  Batch 895/1142 - Loss: 5.2131\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1142/1142 - Loss: 4.5975\n",
      "→ Epoch 44 finished - Avg Loss: 5.0562\n",
      "✅ Best model saved at epoch 44 with loss 5.0562\n",
      "\n",
      "Epoch 45/300\n",
      "  Batch 1142/1142 - Loss: 5.1877\n",
      "→ Epoch 45 finished - Avg Loss: 5.0557\n",
      "✅ Best model saved at epoch 45 with loss 5.0557\n",
      "\n",
      "Epoch 46/300\n",
      "  Batch 441/1142 - Loss: 4.9036\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1142/1142 - Loss: 4.9761\n",
      "→ Epoch 47 finished - Avg Loss: 5.0538\n",
      "✅ Best model saved at epoch 47 with loss 5.0538\n",
      "\n",
      "Epoch 48/300\n",
      "  Batch 159/1142 - Loss: 4.8132\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1142/1142 - Loss: 4.4459\n",
      "→ Epoch 121 finished - Avg Loss: 5.0332\n",
      "✅ Best model saved at epoch 121 with loss 5.0332\n",
      "\n",
      "Epoch 122/300\n",
      "  Batch 1142/1142 - Loss: 5.0327\n",
      "→ Epoch 122 finished - Avg Loss: 5.0333\n",
      "\n",
      "Epoch 123/300\n",
      "  Batch 1142/1142 - Loss: 5.2166\n",
      "→ Epoch 123 finished - Avg Loss: 5.0334\n",
      "\n",
      "Epoch 124/300\n",
      "  Batch 1142/1142 - Loss: 5.5636\n",
      "→ Epoch 124 finished - Avg Loss: 5.0334\n",
      "\n",
      "Epoch 125/300\n",
      "  Batch 613/1142 - Loss: 5.0264\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1142/1142 - Loss: 5.7771\n",
      "→ Epoch 125 finished - Avg Loss: 5.0334\n",
      "\n",
      "Epoch 126/300\n",
      "  Batch 1142/1142 - Loss: 4.9969\n",
      "→ Epoch 126 finished - Avg Loss: 5.0325\n",
      "✅ Best model saved at epoch 126 with loss 5.0325\n",
      "\n",
      "Epoch 127/300\n",
      "  Batch 1142/1142 - Loss: 5.3210\n",
      "→ Epoch 127 finished - Avg Loss: 5.0324\n",
      "✅ Best model saved at epoch 127 with loss 5.0324\n",
      "\n",
      "Epoch 128/300\n",
      "  Batch 1142/1142 - Loss: 5.2161\n",
      "→ Epoch 128 finished - Avg Loss: 5.0322\n",
      "✅ Best model saved at epoch 128 with loss 5.0322\n",
      "\n",
      "Epoch 129/300\n",
      "  Batch 1142/1142 - Loss: 4.3955\n",
      "→ Epoch 129 finished - Avg Loss: 5.0312\n",
      "✅ Best model saved at epoch 129 with loss 5.0312\n",
      "\n",
      "Epoch 130/300\n",
      "  Batch 1142/1142 - Loss: 5.3261\n",
      "→ Epoch 130 finished - Avg Loss: 5.0318\n",
      "\n",
      "Epoch 131/300\n",
      "  Batch 1142/1142 - Loss: 4.9858\n",
      "→ Epoch 131 finished - Avg Loss: 5.0314\n",
      "\n",
      "Epoch 132/300\n",
      "  Batch 1142/1142 - Loss: 5.0769\n",
      "→ Epoch 132 finished - Avg Loss: 5.0311\n",
      "✅ Best model saved at epoch 132 with loss 5.0311\n",
      "\n",
      "Epoch 133/300\n",
      "  Batch 1142/1142 - Loss: 4.9538\n",
      "→ Epoch 133 finished - Avg Loss: 5.0308\n",
      "✅ Best model saved at epoch 133 with loss 5.0308\n",
      "\n",
      "Epoch 134/300\n",
      "  Batch 1142/1142 - Loss: 5.6162\n",
      "→ Epoch 134 finished - Avg Loss: 5.0312\n",
      "\n",
      "Epoch 135/300\n",
      "  Batch 1142/1142 - Loss: 5.0058\n",
      "→ Epoch 135 finished - Avg Loss: 5.0304\n",
      "✅ Best model saved at epoch 135 with loss 5.0304\n",
      "\n",
      "Epoch 136/300\n",
      "  Batch 1142/1142 - Loss: 4.9945\n",
      "→ Epoch 136 finished - Avg Loss: 5.0300\n",
      "✅ Best model saved at epoch 136 with loss 5.0300\n",
      "\n",
      "Epoch 137/300\n",
      "  Batch 1142/1142 - Loss: 5.6507\n",
      "→ Epoch 137 finished - Avg Loss: 5.0305\n",
      "\n",
      "Epoch 138/300\n",
      "  Batch 1142/1142 - Loss: 5.3004\n",
      "→ Epoch 138 finished - Avg Loss: 5.0299\n",
      "✅ Best model saved at epoch 138 with loss 5.0299\n",
      "\n",
      "Epoch 139/300\n",
      "  Batch 1142/1142 - Loss: 5.0569\n",
      "→ Epoch 139 finished - Avg Loss: 5.0295\n",
      "✅ Best model saved at epoch 139 with loss 5.0295\n",
      "\n",
      "Epoch 140/300\n",
      "  Batch 1142/1142 - Loss: 4.8126\n",
      "→ Epoch 140 finished - Avg Loss: 5.0288\n",
      "✅ Best model saved at epoch 140 with loss 5.0288\n",
      "\n",
      "Epoch 141/300\n",
      "  Batch 1142/1142 - Loss: 4.7454\n",
      "→ Epoch 141 finished - Avg Loss: 5.0286\n",
      "✅ Best model saved at epoch 141 with loss 5.0286\n",
      "\n",
      "Epoch 142/300\n",
      "  Batch 1142/1142 - Loss: 5.2319\n",
      "→ Epoch 142 finished - Avg Loss: 5.0289\n",
      "\n",
      "Epoch 143/300\n",
      "  Batch 1142/1142 - Loss: 5.3675\n",
      "→ Epoch 143 finished - Avg Loss: 5.0286\n",
      "✅ Best model saved at epoch 143 with loss 5.0286\n",
      "\n",
      "Epoch 144/300\n",
      "  Batch 1142/1142 - Loss: 4.8422\n",
      "→ Epoch 144 finished - Avg Loss: 5.0282\n",
      "✅ Best model saved at epoch 144 with loss 5.0282\n",
      "\n",
      "Epoch 145/300\n",
      "  Batch 1142/1142 - Loss: 4.9952\n",
      "→ Epoch 145 finished - Avg Loss: 5.0279\n",
      "✅ Best model saved at epoch 145 with loss 5.0279\n",
      "\n",
      "Epoch 146/300\n",
      "  Batch 1142/1142 - Loss: 5.1809\n",
      "→ Epoch 146 finished - Avg Loss: 5.0277\n",
      "✅ Best model saved at epoch 146 with loss 5.0277\n",
      "\n",
      "Epoch 147/300\n",
      "  Batch 1142/1142 - Loss: 4.9375\n",
      "→ Epoch 147 finished - Avg Loss: 5.0272\n",
      "✅ Best model saved at epoch 147 with loss 5.0272\n",
      "\n",
      "Epoch 148/300\n",
      "  Batch 1142/1142 - Loss: 5.3395\n",
      "→ Epoch 148 finished - Avg Loss: 5.0274\n",
      "\n",
      "Epoch 149/300\n",
      "  Batch 1142/1142 - Loss: 4.8493\n",
      "→ Epoch 149 finished - Avg Loss: 5.0268\n",
      "✅ Best model saved at epoch 149 with loss 5.0268\n",
      "\n",
      "Epoch 150/300\n",
      "  Batch 1142/1142 - Loss: 5.2385\n",
      "→ Epoch 199 finished - Avg Loss: 5.0124\n",
      "✅ Best model saved at epoch 199 with loss 5.0124\n",
      "\n",
      "Epoch 200/300\n",
      "  Batch 1142/1142 - Loss: 4.9392\n",
      "→ Epoch 200 finished - Avg Loss: 5.0118\n",
      "✅ Best model saved at epoch 200 with loss 5.0118\n",
      "\n",
      "Epoch 201/300\n",
      "  Batch 1142/1142 - Loss: 4.9632\n",
      "→ Epoch 201 finished - Avg Loss: 5.0115\n",
      "✅ Best model saved at epoch 201 with loss 5.0115\n",
      "\n",
      "Epoch 202/300\n",
      "  Batch 1142/1142 - Loss: 4.8591\n",
      "→ Epoch 202 finished - Avg Loss: 5.0111\n",
      "✅ Best model saved at epoch 202 with loss 5.0111\n",
      "\n",
      "Epoch 203/300\n",
      "  Batch 1142/1142 - Loss: 4.9177\n",
      "→ Epoch 203 finished - Avg Loss: 5.0109\n",
      "✅ Best model saved at epoch 203 with loss 5.0109\n",
      "\n",
      "Epoch 204/300\n",
      "  Batch 1142/1142 - Loss: 5.0156\n",
      "→ Epoch 204 finished - Avg Loss: 5.0106\n",
      "✅ Best model saved at epoch 204 with loss 5.0106\n",
      "\n",
      "Epoch 205/300\n",
      "  Batch 1142/1142 - Loss: 5.2448\n",
      "→ Epoch 205 finished - Avg Loss: 5.0104\n",
      "✅ Best model saved at epoch 205 with loss 5.0104\n",
      "\n",
      "Epoch 206/300\n",
      "  Batch 1142/1142 - Loss: 5.4239\n",
      "→ Epoch 206 finished - Avg Loss: 5.0102\n",
      "✅ Best model saved at epoch 206 with loss 5.0102\n",
      "\n",
      "Epoch 207/300\n",
      "  Batch 1142/1142 - Loss: 5.1883\n",
      "→ Epoch 207 finished - Avg Loss: 5.0097\n",
      "✅ Best model saved at epoch 207 with loss 5.0097\n",
      "\n",
      "Epoch 208/300\n",
      "  Batch 1142/1142 - Loss: 4.8847\n",
      "→ Epoch 208 finished - Avg Loss: 5.0091\n",
      "✅ Best model saved at epoch 208 with loss 5.0091\n",
      "\n",
      "Epoch 209/300\n",
      "  Batch 1142/1142 - Loss: 5.1870\n",
      "→ Epoch 209 finished - Avg Loss: 5.0090\n",
      "✅ Best model saved at epoch 209 with loss 5.0090\n",
      "\n",
      "Epoch 210/300\n",
      "  Batch 1142/1142 - Loss: 5.3260\n",
      "→ Epoch 210 finished - Avg Loss: 5.0087\n",
      "✅ Best model saved at epoch 210 with loss 5.0087\n",
      "\n",
      "Epoch 211/300\n",
      "  Batch 1142/1142 - Loss: 4.7280\n",
      "→ Epoch 216 finished - Avg Loss: 5.0062\n",
      "✅ Best model saved at epoch 216 with loss 5.0062\n",
      "\n",
      "Epoch 217/300\n",
      "  Batch 1142/1142 - Loss: 5.1407\n",
      "→ Epoch 217 finished - Avg Loss: 5.0062\n",
      "\n",
      "Epoch 218/300\n",
      "  Batch 1142/1142 - Loss: 4.6540\n",
      "→ Epoch 218 finished - Avg Loss: 5.0054\n",
      "✅ Best model saved at epoch 218 with loss 5.0054\n",
      "\n",
      "Epoch 219/300\n",
      "  Batch 1142/1142 - Loss: 5.5302\n",
      "→ Epoch 219 finished - Avg Loss: 5.0058\n",
      "\n",
      "Epoch 220/300\n",
      "  Batch 1142/1142 - Loss: 4.8119\n",
      "→ Epoch 220 finished - Avg Loss: 5.0048\n",
      "✅ Best model saved at epoch 220 with loss 5.0048\n",
      "\n",
      "Epoch 221/300\n",
      "  Batch 1142/1142 - Loss: 5.0742\n",
      "→ Epoch 221 finished - Avg Loss: 5.0047\n",
      "✅ Best model saved at epoch 221 with loss 5.0047\n",
      "\n",
      "Epoch 222/300\n",
      "  Batch 1142/1142 - Loss: 5.2272\n",
      "→ Epoch 222 finished - Avg Loss: 5.0045\n",
      "✅ Best model saved at epoch 222 with loss 5.0045\n",
      "\n",
      "Epoch 223/300\n",
      "  Batch 1142/1142 - Loss: 5.0217\n",
      "→ Epoch 223 finished - Avg Loss: 5.0039\n",
      "✅ Best model saved at epoch 223 with loss 5.0039\n",
      "\n",
      "Epoch 224/300\n",
      "  Batch 1142/1142 - Loss: 5.1122\n",
      "→ Epoch 224 finished - Avg Loss: 5.0036\n",
      "✅ Best model saved at epoch 224 with loss 5.0036\n",
      "\n",
      "Epoch 225/300\n",
      "  Batch 1142/1142 - Loss: 4.8482\n",
      "→ Epoch 225 finished - Avg Loss: 5.0031\n",
      "✅ Best model saved at epoch 225 with loss 5.0031\n",
      "\n",
      "Epoch 226/300\n",
      "  Batch 1142/1142 - Loss: 5.1284\n",
      "→ Epoch 226 finished - Avg Loss: 5.0029\n",
      "✅ Best model saved at epoch 226 with loss 5.0029\n",
      "\n",
      "Epoch 227/300\n",
      "  Batch 1142/1142 - Loss: 5.0497\n",
      "→ Epoch 227 finished - Avg Loss: 5.0025\n",
      "✅ Best model saved at epoch 227 with loss 5.0025\n",
      "\n",
      "Epoch 228/300\n",
      "  Batch 1142/1142 - Loss: 5.0632\n",
      "→ Epoch 228 finished - Avg Loss: 5.0022\n",
      "✅ Best model saved at epoch 228 with loss 5.0022\n",
      "\n",
      "Epoch 229/300\n",
      "  Batch 26/1142 - Loss: 4.9695\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1142/1142 - Loss: 5.7716\n",
      "→ Epoch 230 finished - Avg Loss: 5.0020\n",
      "\n",
      "Epoch 231/300\n",
      "  Batch 663/1142 - Loss: 4.9750\r"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Setup TensorBoard\n",
    "writer = SummaryWriter(log_dir='runs/word2vec')\n",
    "\n",
    "# For saving the best model\n",
    "best_loss = float('inf')\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for batch_idx, (central_word, context_word) in enumerate(train_loader):\n",
    "        central_word_onehot = F.one_hot(central_word, num_classes=vocab_size).float().to(device)\n",
    "        context_word_onehot = F.one_hot(context_word, num_classes=vocab_size).float().to(device)\n",
    "\n",
    "        outputs = model(central_word_onehot)\n",
    "        batch_loss = loss_fn(outputs, context_word_onehot)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        batch_loss_value = batch_loss.item()\n",
    "        epoch_loss += batch_loss_value\n",
    "\n",
    "        # Verbose per batch (similar to TensorFlow)\n",
    "        print(f\"  Batch {batch_idx+1}/{len(train_loader)} - Loss: {batch_loss_value:.4f}\", end='\\r')\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"\\n→ Epoch {epoch+1} finished - Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar('Loss/train', avg_loss, epoch + 1)\n",
    "\n",
    "    # Save best model based on loss\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Best model saved at epoch {epoch+1} with loss {best_loss:.4f}\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "072cf955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2336858])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_word_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf5d6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('best_model.pth')\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21f9436a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 11272])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix = model.hidden.weight.data\n",
    "weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b511b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden.weight\n",
      "output.weight\n"
     ]
    }
   ],
   "source": [
    "for name,_ in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bf8055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11272, 500])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix2 = model.output.weight.data\n",
    "weight_matrix2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90aec003",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = word2index['पापी']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cf5b63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix2[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5aa4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word):\n",
    "    idx = word2index[word]\n",
    "    emb = weight_matrix2[idx] + weight_matrix.T[idx]\n",
    "    return emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1729796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_tensors(tensor1, tensor2):\n",
    "    tensor1 = tensor1.float()\n",
    "    tensor2 = tensor2.float()\n",
    "\n",
    "    if tensor1.ndim == 1:\n",
    "        tensor1_normalized = F.normalize(tensor1, p=2, dim=0)\n",
    "        tensor2_normalized = F.normalize(tensor2, p=2, dim=0)\n",
    "    elif tensor1.ndim == 2:\n",
    "        tensor1_normalized = F.normalize(tensor1, p=2, dim=1)\n",
    "        tensor2_normalized = F.normalize(tensor2, p=2, dim=1)\n",
    "    else:\n",
    "        raise ValueError(\"Input tensors should be 1D or 2D.\")\n",
    "    similarity = torch.sum(tensor1_normalized * tensor2_normalized, dim=-1)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b579e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pairs(wrd1,wrd2):\n",
    "    return cosine_similarity_tensors(get_embedding(wrd1), get_embedding(wrd2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae9ddbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2897, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_pairs(\"पापी\",\"पापं\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7bb4b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3712, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_pairs(\"पद्मनाभ\", \"दामोदर\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf6bf8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4786, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_pairs(\"वासुदेवाय\", \"नारायणाय\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8797c9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0122, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_pairs(\"राम\",\"पापं\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sanskritllm",
   "language": "python",
   "name": "sanskritllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
